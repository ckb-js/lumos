# Migration to Lumos@0.19

Migrate from lumos@0.18 or earlier to Lumos@0.19

1. changed all snake_case to camelCase
2. removed the ckb-js-toolkit and replaced with @lumos/codec

## At a Glance

Migration to the new version should contain changes similar to:

```diff
// usage of snake_case types
const lockScript: Script = {
-  code_hash: '0x...',
-  hash_type: "type",
+  codeHash: '0x...',
+  hashHype: "type",
  args: '0x...',
};

// usage of snake_case RPC methods
-  const hash = await rpc.send_transaction(tx, "passthrough");
+  const hash = await rpc.sendTransaction(tx, "passthrough");

// usage of codec
// Deserialization
   const witness = '0x...'
-  const witnessArgs = new core.WitnessArgs(new toolkit.Reader(witness));
-  const lock = witnessArgs.getLock();
+  const witnessArgs = blockchain.WitnessArgs.unpack(bytes.bytify(witness))
+  const lock = witnessArgs.lock;

// Serialization:
   const newWitnessArgs = { lock: '0x...' };
-  witness = new toolkit.Reader(
-    core.SerializeWitnessArgs(toolkit.normalizers.NormalizeWitnessArgs(newWitnessArgs))
-  ).serializeJson();
+  witness = bytes.hexify(blockchain.WitnessArgs.pack(newWitnessArgs))
```

**Tips: If you have persisted data, remember to change them too.**

## Snake-Case to Camel-Case

In the previous version of `@ckb-lumos`, we used snake_case in exposed APIs in RPC object types.

Old version RPC object types: https://github.com/nervosnetwork/lumos/blob/1669bf527c/packages/base/lib/api.d.ts

We unified Lumos' mixed APIs of camel case and snake case into camel case.

### Objects

```diff
export interface Script {
-  code_hash: Hash;
+  codeHash: Hash;
-  hash_type: HashType;
+  hashType: HashType;
  args: HexString;
}
```

### Methods/Functions

Since we have deprecated `Reader` class, the `CKBHasher` will no longer support `Reader`. The `Reader` class was used to transform between `HexString` and `ArrayBuffer`, you can use `bytes` utility in `@ckb-lumos/codec` to the transformations in v0.19.

CKBHaher utility functions: https://github.com/nervosnetwork/lumos/blob/bc3b8f1363/packages/base/lib/utils.d.ts#L7-L15

```diff
  export class CKBHasher {
    update(data: string | Reader | ArrayBuffer): this;
-   digestReader(): Reader;
    digestHex(): Hash;
  }
- export function ckbHash(buffer: ArrayBuffer): Reader;
+ export function ckbHash(data: BytesLike): HexString;
```

Deprecated BigInt ulitity functions in `utils`: https://github.com/nervosnetwork/lumos/blob/bc3b8f1363/packages/base/lib/utils.d.ts#L17-L45

Migrate BigInt utility functions:

```diff
  // use `number` and `bytes` in `@ckb-lumos/codec` package

- const data: HexString = toBigUInt64LECompatible(num)
+ const data: HexString = bytes.bytify(number.Uint64LE.pack(num))

- const data: BI = readBigUInt64LECompatible(u64String)
+ const data: BI = number.Uint64LE.unpack(u64String)

- const data: bigint = readBigUInt64LE(u64String)
+ const data: bigint = number.Uint64LE.unpack(u64String).toBigInt()
```


RPC methods: https://github.com/nervosnetwork/lumos/blob/1669bf527c/packages/rpc/src/index.ts

Indexer RPC methods: https://github.com/nervosnetwork/lumos/blob/1669bf527c/packages/ckb-indexer/src/rpc.ts

```diff
- async send_transaction(
+ async sendTransaction(
    tx: Transaction,
-    outputs_validator?: OutputsValidator
+    outputsValidator?: OutputsValidator
  ): Promise<Hash> {
     ...
  }
```

### A Short Script for Migration Case

[script link](https://gist.github.com/zhangyouxin/e5ddf9b966f611173a01d6c98715c931)

### Serialization and Deserialization

In previous version of `@ckb-lumos/base`, there is a [core.js](https://github.com/nervosnetwork/lumos/blob/1669bf527c/packages/base/lib/core.js) which is auto-generated by [molecule-es](https://github.com/nervosnetwork/moleculec-es). We used this `core` to Serialize/Deserialize data, but it is not ts friendly and need to be `Normalized` and `transformed` before serialization, which may be confusing and hard to use.

Later some time we introduced `@ckb-lumos/codec` to provide better user experience, meanwhile `core.js` is also available.

In the new version, we removed `core.js` and implemented basic codecs in `@ckb-lumos/codec/lib/blockchain`.

#### Example of Serialization and Deserialization

```ts
  const witness = '0x...' 
  // Deserialize witness from bytes start
  // step 1: bytify
  const witnessReader = new toolkit.Reader(witness)
  // step 2: Deserialize
  const witnessArgs = new core.WitnessArgs(witnessReader);
  // Deserialize witness from bytes end

  // use deserialized witness
  const lock = witnessArgs.getLock();
  ...

  const newWitnessArgs = { lock: '0x...' };
  // Serialize object to bytes start
  // step 1: normailzation
  const normalized = toolkit.normalizers.NormalizeWitnessArgs(newWitnessArgs)
  // step 2: serialization
  const serialized = core.SerializeWitnessArgs(normalized)
  // step 3: hexify
  const serializedNewWitnessArgs = new toolkit.Reader(serialized).serializeJson();
  // Serialize object to bytes end
```

#### How to Migrate Serialization and Deserialization

```diff
// Deserialization
       const witness = '0x...'
-      const witnessArgs = new core.WitnessArgs(new toolkit.Reader(witness));
-      const lock = witnessArgs.getLock();
+      const witnessArgs = blockchain.WitnessArgs.unpack(bytes.bytify(witness))
+      const lock = witnessArgs.lock;

// Serialization:
     const newWitnessArgs = { lock: '0x...' };
-    witness = new toolkit.Reader(
-      core.SerializeWitnessArgs(toolkit.normalizers.NormalizeWitnessArgs(newWitnessArgs))
-    ).serializeJson();
+    witness = bytes.hexify(blockchain.WitnessArgs.pack(newWitnessArgs))
```

## A Real World Migration Example

Here is a simple example of how we could migrate [secp256k1-transfer](https://github.com/nervosnetwork/lumos/blob/1669bf527c/examples/secp256k1-transfer/lib.ts) to the new version.

```diff
...

  const lockScript = {
-    code_hash: template.CODE_HASH,
-    hash_type: template.HASH_TYPE,
+    codeHash: template.CODE_HASH,
+    hashType: template.HASH_TYPE,
    args: args,
  };
...
  let balance = BI.from(0);
  for await (const cell of collector.collect()) {
-    balance = balance.add(cell.cell_output.capacity);
+    balance = balance.add(cell.cellOutput.capacity);
  }

...
  const collected: Cell[] = [];
  const collector = indexer.collector({ lock: fromScript, type: "empty" });
  for await (const cell of collector.collect()) {
-    collectedSum = collectedSum.add(cell.cell_output.capacity);
+    collectedSum = collectedSum.add(cell.cellOutput.capacity);
    collected.push(cell);
    if (collectedSum >= neededCapacity) break;
  }
...

  const transferOutput: Cell = {
-    cell_output: {
+    cellOutput: {
      capacity: BI.from(options.amount).toHexString(),
      lock: toScript,
    },
    data: "0x",
  };

  const changeOutput: Cell = {
    cell_output: {
    cellOutput: {
      capacity: collectedSum.sub(neededCapacity).toHexString(),
      lock: fromScript,
    },
...
  txSkeleton = txSkeleton.update("cellDeps", (cellDeps) =>
    cellDeps.push({
-      out_point: {
-        tx_hash: AGGRON4.SCRIPTS.SECP256K1_BLAKE160.TX_HASH,
+      outPoint: {
+        txHash: AGGRON4.SCRIPTS.SECP256K1_BLAKE160.TX_HASH,
        index: AGGRON4.SCRIPTS.SECP256K1_BLAKE160.INDEX,
      },
-      dep_type: AGGRON4.SCRIPTS.SECP256K1_BLAKE160.DEP_TYPE,
+      depType: AGGRON4.SCRIPTS.SECP256K1_BLAKE160.DEP_TYPE,
    })
  );

  const firstIndex = txSkeleton
    .get("inputs")
    .findIndex((input) =>
-      new ScriptValue(input.cell_output.lock, { validate: false }).equals(
+      new ScriptValue(input.cellOutput.lock, { validate: false }).equals(
        new ScriptValue(fromScript, { validate: false })
      )
    );
...
    if (witness !== "0x") {
-      const witnessArgs = new core.WitnessArgs(new toolkit.Reader(witness));
-      const lock = witnessArgs.getLock();
-      if (lock.hasValue() && new toolkit.Reader(lock.value().raw()).serializeJson() !== newWitnessArgs.lock) {
+      const witnessArgs = blockchain.WitnessArgs.unpack(bytes.bytify(witness))
+      const lock = witnessArgs.lock;
+      if (!!lock && lock !== newWitnessArgs.lock) {
        throw new Error("Lock field in first witness is set aside for signature!");
      }
-      const inputType = witnessArgs.getInputType();
-      if (inputType.hasValue()) {
-        newWitnessArgs.input_type = new toolkit.Reader(inputType.value().raw()).serializeJson();
+      const inputType = witnessArgs.inputType;
+      if (!!inputType) {
+        newWitnessArgs.inputType = inputType;
      }
-      const outputType = witnessArgs.getOutputType();
-      if (outputType.hasValue()) {
-        newWitnessArgs.output_type = new toolkit.Reader(outputType.value().raw()).serializeJson();
+      const outputType = witnessArgs.outputType;
+      if (!!outputType) {
+        newWitnessArgs.outputType = outputType;
      }
    }
-    witness = new toolkit.Reader(
-      core.SerializeWitnessArgs(toolkit.normalizers.NormalizeWitnessArgs(newWitnessArgs))
-    ).serializeJson();
+    witness = bytes.hexify(blockchain.WitnessArgs.pack(newWitnessArgs))
    txSkeleton = txSkeleton.update("witnesses", (witnesses) => witnesses.set(firstIndex, witness));
  }

  txSkeleton = commons.common.prepareSigningEntries(txSkeleton);
  const message = txSkeleton.get("signingEntries").get(0)?.message;
  const Sig = hd.key.signRecoverable(message!, options.privKey);
  const tx = helpers.sealTransaction(txSkeleton, [Sig]);
-  const hash = await rpc.send_transaction(tx, "passthrough");
+  const hash = await rpc.sendTransaction(tx, "passthrough");
  console.log("The transaction hash is", hash);

  return hash;
```
